var documenterSearchIndex = {"docs":
[{"location":"ConfidenceNormal/#Calculation-for-Confidence-MvNormal","page":"Calculation for Confidence MvNormal","title":"Calculation for Confidence MvNormal","text":"","category":"section"},{"location":"ConfidenceNormal/","page":"Calculation for Confidence MvNormal","title":"Calculation for Confidence MvNormal","text":"Suppose we have a normal distribution with mean mu and covariance Sigma. The ConfidenceMvNormal with parameters μ, Σ and α represents the truncated distribution on an ellipsoid centered at mu, with 0 leq alpha leq 1 probability mass.","category":"page"},{"location":"ConfidenceNormal/#Standardization","page":"Calculation for Confidence MvNormal","title":"Standardization","text":"","category":"section"},{"location":"ConfidenceNormal/","page":"Calculation for Confidence MvNormal","title":"Calculation for Confidence MvNormal","text":"We start by calculating the Cholesky factorization of Sigma = LL^top. Then, we standardize the distribution by defining z = L^-1(x - mu).","category":"page"},{"location":"ConfidenceNormal/#Ellipsoid-radius","page":"Calculation for Confidence MvNormal","title":"Ellipsoid radius","text":"","category":"section"},{"location":"ConfidenceNormal/","page":"Calculation for Confidence MvNormal","title":"Calculation for Confidence MvNormal","text":"We then need to find rho such that the mass of L cdot B(0 rho) + mu is equal to alpha. This is equivalent to finding rho such that the mass of B(0 rho) is equal to alpha under the standard normal d-dimensional distribution. That is, we need to find rho such that","category":"page"},{"location":"ConfidenceNormal/","page":"Calculation for Confidence MvNormal","title":"Calculation for Confidence MvNormal","text":"alpha \n= sqrt(2pi)^-d int_B(0 rho)  e^-frac12 z^2 dz\n= sqrt(2pi)^-d cdot textVol(S^d-1) int_0^rho t^d-1 e^-t^22 dt","category":"page"},{"location":"ConfidenceNormal/","page":"Calculation for Confidence MvNormal","title":"Calculation for Confidence MvNormal","text":"Integrating the probability density over the entire space gives","category":"page"},{"location":"ConfidenceNormal/","page":"Calculation for Confidence MvNormal","title":"Calculation for Confidence MvNormal","text":"1 = (2pi)^-d2 int_mathbbR^d e^-frac12 z^2 dz\n= (2pi)^-d2 cdot textVol(S^d-1) int_0^infty t^d-1 e^-t^22 dt","category":"page"},{"location":"ConfidenceNormal/","page":"Calculation for Confidence MvNormal","title":"Calculation for Confidence MvNormal","text":"so that alpha = fracint_0^rho t^d-1 e^-t^22 dtint_0^infty t^d-1 e^-t^22 dt.","category":"page"},{"location":"ConfidenceNormal/#Covariance-matrix","page":"Calculation for Confidence MvNormal","title":"Covariance matrix","text":"","category":"section"},{"location":"ConfidenceNormal/","page":"Calculation for Confidence MvNormal","title":"Calculation for Confidence MvNormal","text":"Finally, we must calculate the covariance matrix of the truncated distribution. It is, by definition:","category":"page"},{"location":"ConfidenceNormal/","page":"Calculation for Confidence MvNormal","title":"Calculation for Confidence MvNormal","text":"frac1alpha sqrt(2pi)^d det Sigmaint_L cdot B(0 rho) + mu (x - mu) (x - mu)^top e^-frac12 (x - mu)^top Sigma^-1 (x - mu) dx","category":"page"},{"location":"ConfidenceNormal/","page":"Calculation for Confidence MvNormal","title":"Calculation for Confidence MvNormal","text":"The standardization yields:","category":"page"},{"location":"ConfidenceNormal/","page":"Calculation for Confidence MvNormal","title":"Calculation for Confidence MvNormal","text":"frac1alpha sqrt(2pi)^dint_B(0 rho) L z z^top L^top e^-frac12 z^2 dz","category":"page"},{"location":"ConfidenceNormal/","page":"Calculation for Confidence MvNormal","title":"Calculation for Confidence MvNormal","text":"And a polar change of variables z = t cdot omega leads to:","category":"page"},{"location":"ConfidenceNormal/","page":"Calculation for Confidence MvNormal","title":"Calculation for Confidence MvNormal","text":"frac1alpha sqrt(2pi)^dint_0^rho int_S^d-1 L t^2 omega omega^top L^top e^-frac12 t^2 t^d-1  domega dt\n= fracint_0^rho t^d+1 e^-t^22 dtalpha sqrt2pi^d L M_d L^top","category":"page"},{"location":"ConfidenceNormal/","page":"Calculation for Confidence MvNormal","title":"Calculation for Confidence MvNormal","text":"This depends on a matrix M_d = int_S^d-1 omega omega^top domega. It is easy to show that M_d must be a multiple of the identity matrix: an analogous argument shows that the covariance of the standard multivariate normal is frac1sqrt2pi^d int_0^infty t^2 t^d-1 M_d e^-t^22 dt. So M_d = sqrt2pi^d big( int_0^infty t^d+1 e^-t^22 dt big)^-1 I.","category":"page"},{"location":"ConfidenceNormal/","page":"Calculation for Confidence MvNormal","title":"Calculation for Confidence MvNormal","text":"Putting this all together, we obtain displaystyle C_dalpha = frac1alpha fracint_0^rho t^d+1 e^-t^22 dtint_0^infty t^d+1 e^-t^22 dt L L^top.","category":"page"},{"location":"ConfidenceNormal/#Numerical-evaluation","page":"Calculation for Confidence MvNormal","title":"Numerical evaluation","text":"","category":"section"},{"location":"ConfidenceNormal/","page":"Calculation for Confidence MvNormal","title":"Calculation for Confidence MvNormal","text":"To find the radius rho and the scaling of the covariance matrix, we need a change of variables and the gamma functions","category":"page"},{"location":"ConfidenceNormal/","page":"Calculation for Confidence MvNormal","title":"Calculation for Confidence MvNormal","text":"beginalign*\ntextcomplete  Gamma(a)  = int_0^infty u^a-1 e^-u  du \ntextlower incomplete  gamma(a x)  = int_0^x u^a-1 e^-u  du \ntextupper incomplete  Gamma(a x)  = int_x^infty u^a-1 e^-u  du \nendalign*","category":"page"},{"location":"ConfidenceNormal/#Finding-\\rho","page":"Calculation for Confidence MvNormal","title":"Finding rho","text":"","category":"section"},{"location":"ConfidenceNormal/","page":"Calculation for Confidence MvNormal","title":"Calculation for Confidence MvNormal","text":"We had displaystyle alpha = fracint_0^rho t^d-1 e^-t^22  dtint_0^infty t^d-1 e^-t^22  dt.","category":"page"},{"location":"ConfidenceNormal/","page":"Calculation for Confidence MvNormal","title":"Calculation for Confidence MvNormal","text":"With u = t^22, we get du = t  dt and the integrals become","category":"page"},{"location":"ConfidenceNormal/","page":"Calculation for Confidence MvNormal","title":"Calculation for Confidence MvNormal","text":"beginalign*\nalpha cdot int_0^infty t^d-1 e^-t^22  dt\n = int_0^rho t^d-1 e^-t^22  dt \nalpha cdot int_0^infty sqrt2u^d-2 e^-u  du\n = int_0^rho^22 sqrt2u^d-2 e^-u  du \nalpha cdot Gamma(d2)  = gamma(d2 rho^22)\nendalign*","category":"page"},{"location":"ConfidenceNormal/","page":"Calculation for Confidence MvNormal","title":"Calculation for Confidence MvNormal","text":"So rho^2 = 2 gamma^-1(d2 alpha cdot Gamma(d2)).","category":"page"},{"location":"ConfidenceNormal/","page":"Calculation for Confidence MvNormal","title":"Calculation for Confidence MvNormal","text":"If alpha is near 1, it might be more stable to evaluate Gamma^-1(d2 (1 - alpha) cdot Gamma(d2)).","category":"page"},{"location":"ConfidenceNormal/#Finding-the-scaling","page":"Calculation for Confidence MvNormal","title":"Finding the scaling","text":"","category":"section"},{"location":"ConfidenceNormal/","page":"Calculation for Confidence MvNormal","title":"Calculation for Confidence MvNormal","text":"We need to evaluate the ratio of integrals in displaystyle C_dalpha = frac1alpha fracint_0^rho t^d+1 e^-t^22 dtint_0^infty t^d+1 e^-t^22 dt L L^top.","category":"page"},{"location":"ConfidenceNormal/","page":"Calculation for Confidence MvNormal","title":"Calculation for Confidence MvNormal","text":"The same change of variables leads to","category":"page"},{"location":"ConfidenceNormal/","page":"Calculation for Confidence MvNormal","title":"Calculation for Confidence MvNormal","text":"beginalign*\nint_0^rho t^d+1 e^-t^22 dt\n = int_0^rho^22 (2u)^d2 e^-u  du \n = 2^d2 gamma(d2 + 1 rho^22) \nint_0^infty t^d+1 e^-t^22 dt\n = 2^d2 gamma(d2 + 1 infty) = 2^d2 Gamma(d2 + 1) endalign*","category":"page"},{"location":"ConfidenceNormal/","page":"Calculation for Confidence MvNormal","title":"Calculation for Confidence MvNormal","text":"As alpha cdot Gamma(d2) = gamma(d2 rho^22), using integration by parts, we have an alternative expression for the scaling factor:","category":"page"},{"location":"ConfidenceNormal/","page":"Calculation for Confidence MvNormal","title":"Calculation for Confidence MvNormal","text":"fracgamma(d2+1 rho^22)gamma(d2 rho^22) fracGamma(d2)Gamma(d2+1) = fracd2 - (rho^22)^d2e^-rho^22d2","category":"page"},{"location":"pwl/#Piecewise-linear-lifts","page":"Piecewise linear lifts","title":"Piecewise linear lifts","text":"","category":"section"},{"location":"pwl/","page":"Piecewise linear lifts","title":"Piecewise linear lifts","text":"If we generalize the linear decision rule to a piecewise linear decision rule, we can get a better approximation of the optimal decision rule.","category":"page"},{"location":"pwl/","page":"Piecewise linear lifts","title":"Piecewise linear lifts","text":"This implies some changes in the structure of the problem. For simplicity, we will assume that we have a single coordinate of the uncertainty η.","category":"page"},{"location":"pwl/#Breakpoints-and-modification-of-the-uncertainty-polyhedron-Ξ","page":"Piecewise linear lifts","title":"Breakpoints and modification of the uncertainty polyhedron Ξ","text":"","category":"section"},{"location":"pwl/","page":"Piecewise linear lifts","title":"Piecewise linear lifts","text":"We will assume that the uncertainty η is a scalar random variable, and that the uncertainty polyhedron Xi is a segment 1 times η_min η_max. We assume the breakpoints are given by η_0 = η_min  η_1  dots  η_k = η_max. The lengths of the segments are Δ_i = η_i - η_i-1.","category":"page"},{"location":"pwl/","page":"Piecewise linear lifts","title":"Piecewise linear lifts","text":"The random variable eta will be the sum of its components along the segments, i.e.,","category":"page"},{"location":"pwl/","page":"Piecewise linear lifts","title":"Piecewise linear lifts","text":"eta = eta_min + tildeeta_1 + dots + tildeeta_k = eta_min  1 cdots  1 cdot tildeeta = eta_min + e^top tildeeta","category":"page"},{"location":"pwl/","page":"Piecewise linear lifts","title":"Piecewise linear lifts","text":"where tildeeta = tildeeta_1 dots tildeeta_k is the lifted vector corresponding to eta and e = 1 dots 1.","category":"page"},{"location":"pwl/","page":"Piecewise linear lifts","title":"Piecewise linear lifts","text":"So a previous constraint of the form W_u eta leq h_u becomes W_u (eta_min + e^top tildeeta) leq h_u, which defines a matrix tildeW_u = W_u e^top and modifies the right-hand side vector to tildeh_u = h_u - W_u eta_min. In this example, eta is a 1-dimensional random variable, so W_u is a column vector. If we were lifting several variables, this expansion of the coefficient matrix would have to be performed column by column.","category":"page"},{"location":"pwl/","page":"Piecewise linear lifts","title":"Piecewise linear lifts","text":"Furthermore, we observe that the lifted vector tildeeta describes a piecewise linear path, whose vertices are (0 0 ldots 0), (Delta_1 0 ldots 0), (Delta_1 Delta_2 ldots 0), ldots, (Delta_1 Delta_2 ldots Delta_k). The convex hull of these vertices is given by the inequalities","category":"page"},{"location":"pwl/","page":"Piecewise linear lifts","title":"Piecewise linear lifts","text":"beginalign*\n0 leq fractildeeta_kΔ_k leq dots leq fractildeeta_2Δ_2 leq fractildeeta_1Δ_1 leq 1\nendalign*","category":"page"},{"location":"pwl/","page":"Piecewise linear lifts","title":"Piecewise linear lifts","text":"which are to be added to the constraints defining the lifted uncertainty polyhedron tildeXi.","category":"page"},{"location":"pwl/#Modification-of-decisions-and-constraints","page":"Piecewise linear lifts","title":"Modification of decisions and constraints","text":"","category":"section"},{"location":"pwl/","page":"Piecewise linear lifts","title":"Piecewise linear lifts","text":"We must rewrite the decisions constraints in terms of the lifted variable tildexi = 1 tildeeta. The PWL decision rule x(xi) = X xi will be replaced by x(xi) = tildeX tildexi, which poses no additionnal difficulty.","category":"page"},{"location":"pwl/","page":"Piecewise linear lifts","title":"Piecewise linear lifts","text":"The data terms (b_e, ...) are already exact linear functions of xi, so their transformation is similar to the one for the polyhedron constraints. For example, right-hand side b_e(ξ) = B_e xi becomes:","category":"page"},{"location":"pwl/","page":"Piecewise linear lifts","title":"Piecewise linear lifts","text":"beginalign*\nb_e(ξ) = B_e xi  = B_e0  B_eeta 1 eta \n = B_e0 + B_eetaeta \n = B_e0 + B_eeta(eta_min + e^top tildeeta) \n = (B_e0 + B_eetaeta_min)   B_eeta e^top 1 tildeeta\nendalign*","category":"page"},{"location":"pwl/","page":"Piecewise linear lifts","title":"Piecewise linear lifts","text":"and therefore the equality constraint A_e x(ξ) = b_e(ξ) becomes","category":"page"},{"location":"pwl/","page":"Piecewise linear lifts","title":"Piecewise linear lifts","text":"beginalign*\nA_e tildeX = (B_e0 + B_eetaeta_min)   B_eeta e^top\nendalign*","category":"page"},{"location":"pwl/","page":"Piecewise linear lifts","title":"Piecewise linear lifts","text":"Again, this expansion of the coefficient matrix would have to be performed column by column if we were lifting several variables.","category":"page"},{"location":"pwl/#Second-moment-matrix","page":"Piecewise linear lifts","title":"Second-moment matrix","text":"","category":"section"},{"location":"pwl/","page":"Piecewise linear lifts","title":"Piecewise linear lifts","text":"We need to rewrite the second-moment matrix Eξ ξ^top, which is now Etildexi tildexi^top. We must take into account that the coordinates of tildeeta are not independent.","category":"page"},{"location":"pwl/#Uniform-variable-with-breakpoints","page":"Piecewise linear lifts","title":"Uniform variable with breakpoints","text":"","category":"section"},{"location":"pwl/","page":"Piecewise linear lifts","title":"Piecewise linear lifts","text":"If eta is uniformly distributed on the segment η_min η_max, and its lifted vector is tildeeta = tildeeta_1 dots tildeeta_k, then the (ij) entry in the second-moment matrix is given by","category":"page"},{"location":"pwl/","page":"Piecewise linear lifts","title":"Piecewise linear lifts","text":"m_ij = Etildeeta_i tildeeta_j\n= int_0^Delta min(Delta_i max(0 x - eta_i-1)) min(Delta_j max(0 x - eta_j-1))  dx","category":"page"},{"location":"pwl/","page":"Piecewise linear lifts","title":"Piecewise linear lifts","text":"For i  j, these integrals can be split in three parts:","category":"page"},{"location":"pwl/","page":"Piecewise linear lifts","title":"Piecewise linear lifts","text":"for x  eta_j-1, the integrand is zero;\nfor eta_j-1 leq x  eta_j, the integrand is Delta_i (x - eta_j-1), so we have int_eta_j-1^eta_j Delta_i (x - eta_j-1)  rho(x) dx = Delta_i E_texttruncated etax - eta_j-1 cdot Peta_j-1  eta  eta_j;\nfor eta_j leq x  eta_max, the integrand is Delta_i Delta_j, and its contribution is Delta_i Delta_j cdot Peta  eta_j.","category":"page"},{"location":"pwl/","page":"Piecewise linear lifts","title":"Piecewise linear lifts","text":"When i = j, the integrand for x in eta_i-1 eta_i is (x - eta_i-1)^2, so we have: int_eta_j-1^eta_j (x - eta_i-1)^2  rho(x) dx = E_texttruncated eta(x - eta_j-1)^2 cdot Peta_j-1  eta  eta_j","category":"page"},{"location":"pwl/","page":"Piecewise linear lifts","title":"Piecewise linear lifts","text":"The other two are still given by the same formula as above.","category":"page"},{"location":"pwl/#Packages","page":"Piecewise linear lifts","title":"Packages","text":"","category":"section"},{"location":"pwl/","page":"Piecewise linear lifts","title":"Piecewise linear lifts","text":"We rely on the truncated(dist, a, b) mechanism of Distributions.jl to generate the truncations, and on the expectation numerical integration from the Expectations package for integration. Specific distributions (Uniform and Normal) have mean and variance directly calculated by the Distributions.jl package.","category":"page"},{"location":"pwl/","page":"Piecewise linear lifts","title":"Piecewise linear lifts","text":"The integrals are performed with FastGaussQuadrature.jl, which implements several Gauss quadrature rules, which are dispatched by the Expectations package with a reasonable setting. In principle, we could override the use of truncation + expectation by directly using the Gauss quadrature rules for numerical integration.","category":"page"},{"location":"pwl/#Implementation-details","page":"Piecewise linear lifts","title":"Implementation details","text":"","category":"section"},{"location":"pwl/","page":"Piecewise linear lifts","title":"Piecewise linear lifts","text":"Currently, the lift is not performed exactly as described above, but in an affine transformation:","category":"page"},{"location":"pwl/","page":"Piecewise linear lifts","title":"Piecewise linear lifts","text":"eta = tildeeta_1 + dots + tildeeta_k = e^top tildeeta","category":"page"},{"location":"pwl/","page":"Piecewise linear lifts","title":"Piecewise linear lifts","text":"where the first coordinate now includes the lower bound eta_min.","category":"page"},{"location":"pwl/","page":"Piecewise linear lifts","title":"Piecewise linear lifts","text":"The bounding box constraints are now eta_min leq tildeeta_1 leq eta_1, and 0 leq tildeeta_k leq eta_k - eta_k-1 for k geq 2, and the convex hull inequalities need to shift the first one to:","category":"page"},{"location":"pwl/","page":"Piecewise linear lifts","title":"Piecewise linear lifts","text":"fractildeeta_2eta_2 - eta_1 leq fractildeeta_1 - eta_mineta_1 - eta_min","category":"page"},{"location":"pwl/","page":"Piecewise linear lifts","title":"Piecewise linear lifts","text":"This also changes the way to evaluate expectations of the first component, which also trickles down to the second-moment matrix (the covariance matrix is the same, but we do not need to calculate it explicitly).","category":"page"},{"location":"pwl/","page":"Piecewise linear lifts","title":"Piecewise linear lifts","text":"On the other hand, this does not change the constant part of the RHS matrix B: only the expansion is needed.","category":"page"},{"location":"math/#Mathematical-formulations","page":"Mathematical formulations","title":"Mathematical formulations","text":"","category":"section"},{"location":"math/","page":"Mathematical formulations","title":"Mathematical formulations","text":"We follow the scheme from Primal and dual linear decision rules in stochastic and robust optimization, by Kuhn, Wiesemann and Georghiou.","category":"page"},{"location":"math/#Derivation-of-primal-LDR-problem","page":"Mathematical formulations","title":"Derivation of primal LDR problem","text":"","category":"section"},{"location":"math/","page":"Mathematical formulations","title":"Mathematical formulations","text":"We start from","category":"page"},{"location":"math/","page":"Mathematical formulations","title":"Mathematical formulations","text":"beginarrayrl\nmin   E c(ξ)^top x(ξ) + x(ξ)^top Q x(ξ) + r  05ex\ntextst  A_e x(ξ) = b_e(ξ) \n A_u x(ξ)  b_u(ξ) \n A_l x(ξ)  b_l(ξ) \n x(ξ)  x_u \n x(ξ)  x_l \n x_i(ξ) text is non-anticipative for  i  I \n  ξ  Ξ\nendarray","category":"page"},{"location":"math/","page":"Mathematical formulations","title":"Mathematical formulations","text":"where Ξ  ℝ^m is a polytope described by","category":"page"},{"location":"math/","page":"Mathematical formulations","title":"Mathematical formulations","text":"beginalign*\nΞ  =  ξ = (1 η)  ℝ^m mid W_u η  h_u W_l η  h_l lb  η  ub  \n =  ξ  ℝ^m mid W ξ  h \nendalign*","category":"page"},{"location":"math/","page":"Mathematical formulations","title":"Mathematical formulations","text":"Recall that the linear span of Ξ must be all of ℝ^m.","category":"page"},{"location":"math/","page":"Mathematical formulations","title":"Mathematical formulations","text":"We introduce positive slack variables for the inequality constraints, so that the problem can be written as","category":"page"},{"location":"math/","page":"Mathematical formulations","title":"Mathematical formulations","text":"beginarrayrl\nmin   E c(ξ)^top x(ξ) + x(ξ)^top Q x(ξ) + r  05ex\ntextst  A_e x(ξ) = b_e(ξ) \n A_u x(ξ) + s_u(ξ) = b_u(ξ) \n A_l x(ξ) - s_l(ξ) = b_l(ξ) \n x(ξ) + s_xu(ξ) = x_u \n x(ξ) - s_xl(ξ) = x_l \n s_u(ξ)  0 \n s_l(ξ)  0 \n s_xu(ξ)  0 \n s_xl(ξ)  0 \n  ξ  Ξ\nendarray","category":"page"},{"location":"math/","page":"Mathematical formulations","title":"Mathematical formulations","text":"Assuming a linear decision rule x(ξ) = X ξ, etc, and that scenario-dependent data c(ξ), b_e(ξ), b_u(ξ), b_l(ξ) can also be transformed to linear forms, we write the problem as","category":"page"},{"location":"math/","page":"Mathematical formulations","title":"Mathematical formulations","text":"beginarrayrl\nmin   E ξ^top C^top X ξ + ξ^top X^top Q X ξ + r  05ex\ntextst  A_e X ξ = B_e ξ \n A_u X ξ + S_u ξ = B_u ξ \n A_l X ξ - S_l ξ = B_l ξ \n X ξ + S_xu ξ = X_u ξ \n X ξ - S_xl ξ = X_l ξ \n S_u ξ  0 \n S_l ξ  0 \n S_xu ξ  0 \n S_xl ξ  0 \n  ξ  Ξ\nendarray","category":"page"},{"location":"math/","page":"Mathematical formulations","title":"Mathematical formulations","text":"where X_u = x_u 0 and X_l = x_l 0, since the first component of ξ is equal to 1 by definition.","category":"page"},{"location":"math/","page":"Mathematical formulations","title":"Mathematical formulations","text":"Since the linear span of Ξ is all of ℝ^m, the equalities must hold for all ξ, so they can be replaced by equalities between the corresponding matrices. Moreover, applying the trace trick to the objective function, we obtain","category":"page"},{"location":"math/","page":"Mathematical formulations","title":"Mathematical formulations","text":"beginarrayrl\nmin   texttrBig( (C^top X + X^top Q X) Eξ ξ^top Big) + r 05ex\ntextst  A_e X = B_e \n A_u X + S_u = B_u \n A_l X - S_l = B_l \n X + S_xu = X_u \n X - S_xl = X_l \n S_u ξ  0 \n S_l ξ  0 \n S_xu ξ  0 \n S_xl ξ  0 \n  ξ  Ξ\nendarray","category":"page"},{"location":"math/","page":"Mathematical formulations","title":"Mathematical formulations","text":"The non-negativity constraints are dealt with by duality. If S ξ  0 for all ξ in Ξ =  ξ  ℝ^m mid W ξ  h , then there exists a matrix Λ  0 such that S = Λ W and Λ h  0. Therefore, we introduce the matrices Λ_Su, Λ_Sl, Λ_Sxu, Λ_Sxl and obtain the equivalent problem","category":"page"},{"location":"math/","page":"Mathematical formulations","title":"Mathematical formulations","text":"beginarrayrl\nmin   texttrBig( (C^top X + X^top Q X) Eξ ξ^top Big) + r 05ex\ntextst  A_e X = B_e \n A_u X + S_u = B_u \n A_l X - S_l = B_l \n X + S_xu = X_u \n X - S_xl = X_l \n S_u = Λ_Su W \n S_l = Λ_Sl W \n S_xu = Λ_Sxu W \n S_xl = Λ_Sxl W \n Λ_Su h  0 \n Λ_Sl h  0 \n Λ_Sxu h  0 \n Λ_Sxl h  0 \n Λ_Su  0 \n Λ_Sl  0 \n Λ_Sxu  0 \n Λ_Sxl  0\nendarray","category":"page"},{"location":"math/#Derivation-of-dual-LDR-problem","page":"Mathematical formulations","title":"Derivation of dual LDR problem","text":"","category":"section"},{"location":"math/","page":"Mathematical formulations","title":"Mathematical formulations","text":"Imposing a linear decision rule on the constraint multipliers corresponds to a relaxation of the primal problem, where constraints are taken as expectation. For example, the equality constraints become:","category":"page"},{"location":"math/","page":"Mathematical formulations","title":"Mathematical formulations","text":"E (A_e x(ξ) - b_e(ξ)) ξ^top  = 0","category":"page"},{"location":"math/","page":"Mathematical formulations","title":"Mathematical formulations","text":"If the second-moment matrix M = Eξ ξ^top is invertible, we are justified to search for x(ξ) in the form X ξ, since for every x(ξ) there is an X such that E x(ξ) ξ^top  = X M.","category":"page"},{"location":"math/","page":"Mathematical formulations","title":"Mathematical formulations","text":"The slack variables s_cdot(xi) remain scenario-wise positive, and we demand that E s_cdot(ξ) ξ^top  = S_cdot M for the reformulation of the inequality constraints. Again using duality, this leads to the constraints (W - h e_0^top) M S_cdot^top  0, where e_0 is the first canonical vector.","category":"page"},{"location":"math/","page":"Mathematical formulations","title":"Mathematical formulations","text":"Then, the reformulation of the dual LDR problem is","category":"page"},{"location":"math/","page":"Mathematical formulations","title":"Mathematical formulations","text":"beginarrayrl\nmin   texttrBig( (C^top X + X^top Q X) Eξ ξ^top Big) + r 05ex\ntextst  A_e X = B_e \n A_u X + S_u = B_u \n A_l X - S_l = B_l \n X + S_xu = X_u \n X - S_xl = X_l \n (W - h e_0^top) M S_u^top  0 \n (W - h e_0^top) M S_l^top  0 \n (W - h e_0^top) M S_xu^top  0 \n (W - h e_0^top) M S_xl^top  0\nendarray","category":"page"},{"location":"#LinearDecisionRules.jl-Documentation","page":"LinearDecisionRules.jl Documentation","title":"LinearDecisionRules.jl Documentation","text":"","category":"section"},{"location":"","page":"LinearDecisionRules.jl Documentation","title":"LinearDecisionRules.jl Documentation","text":"The LinearDecisionRules.jl package provides a simple JuMP abstraction to represent decision rules in (stochastic) optimization problems as linear functions of random variables.","category":"page"},{"location":"","page":"LinearDecisionRules.jl Documentation","title":"LinearDecisionRules.jl Documentation","text":"The problems the package deals with are of the form","category":"page"},{"location":"","page":"LinearDecisionRules.jl Documentation","title":"LinearDecisionRules.jl Documentation","text":"beginarrayrl\nmin   mathbbE_ξ  c(ξ)^top x(ξ) + x(ξ)^top Q x(ξ) + r  05ex\ntextst  A_e x(ξ) = b_e(ξ) \n A_u x(ξ)  b_u(ξ) \n A_l x(ξ)  b_l(ξ) \n x(ξ)  x_u \n x(ξ)  x_l \n x_i(ξ) text is non-anticipative for  i  I \n  ξ  Ξ\nendarray","category":"page"},{"location":"","page":"LinearDecisionRules.jl Documentation","title":"LinearDecisionRules.jl Documentation","text":"where Ξ  ℝ^m is a polytope described by","category":"page"},{"location":"","page":"LinearDecisionRules.jl Documentation","title":"LinearDecisionRules.jl Documentation","text":"beginalign*\nΞ  =  ξ = (1 η)  ℝ^m mid W_u η  h_u W_l η  h_l lb  η  ub  \n =  ξ  ℝ^m mid W ξ  h \nendalign*","category":"page"},{"location":"","page":"LinearDecisionRules.jl Documentation","title":"LinearDecisionRules.jl Documentation","text":"Variable η cannot appear in equality constraints in the equations for Xi, since the linear span of Ξ must be all of ℝ^m.","category":"page"},{"location":"","page":"LinearDecisionRules.jl Documentation","title":"LinearDecisionRules.jl Documentation","text":"Non-anticipative variables are not allowed to depend on the random variable ξ. This is enforced by fixing their decision rules to have coefficient equal to zero, except for the constant term. However, non-anticipative variables can be declared as integer (or binary) as they appear directly in the resulting QP.","category":"page"},{"location":"#Example","page":"LinearDecisionRules.jl Documentation","title":"Example","text":"","category":"section"},{"location":"","page":"LinearDecisionRules.jl Documentation","title":"LinearDecisionRules.jl Documentation","text":"Consider the following classical \"Newsvendor\" problem:","category":"page"},{"location":"","page":"LinearDecisionRules.jl Documentation","title":"LinearDecisionRules.jl Documentation","text":"A retailer must decide how many units of a product to buy (at a cost of $10).\nThe demand is uniformly distributed between 80 and 120 units, and unavailable at buying time; units are sold for $15.\nLeftover units can be returned (for $8).","category":"page"},{"location":"","page":"LinearDecisionRules.jl Documentation","title":"LinearDecisionRules.jl Documentation","text":"This leads to the following optimization problem:","category":"page"},{"location":"","page":"LinearDecisionRules.jl Documentation","title":"LinearDecisionRules.jl Documentation","text":"beginarrayrl\nmax   - 10 cdot textbuy + mathbbE  8 cdot textreturn + 15 cdot textsell 05ex\ntextst  textsell(ξ) + textreturn(ξ)  textbuy \n textsell(ξ)  textdemand(ξ) \n 0  textsell(ξ) textreturn(ξ) textbuy\nendarray","category":"page"},{"location":"","page":"LinearDecisionRules.jl Documentation","title":"LinearDecisionRules.jl Documentation","text":"where we indicate that buy is a first-stage decision, and sell and return are second-stage decisions, depending on the scenario xi that fixes value of the random variable demand.","category":"page"},{"location":"","page":"LinearDecisionRules.jl Documentation","title":"LinearDecisionRules.jl Documentation","text":"using JuMP\nusing LinearDecisionRules\nusing HiGHS\nusing Distributions\n\nbuy_cost = 10\nreturn_value = 8\nsell_value = 15\n\ndemand_max = 120\ndemand_min = 80\n\nldr = LinearDecisionRules.LDRModel(HiGHS.Optimizer)\nset_silent(ldr)\n\n@variable(ldr, buy >= 0, LinearDecisionRules.FirstStage)\n@variable(ldr, sell >= 0)\n@variable(ldr, ret >= 0)\n@variable(ldr, demand in LinearDecisionRules.Uncertainty(\n        distribution = Uniform(demand_min, demand_max)\n    )\n)\n\n@constraint(ldr, sell + ret <= buy)\n@constraint(ldr, sell <= demand)\n\n@objective(ldr, Max,\n    - buy_cost * buy\n    + return_value * ret\n    + sell_value * sell\n)\n\noptimize!(ldr)\n\n@show objective_value(ldr)\n@show LinearDecisionRules.get_decision(ldr, buy)\n@show LinearDecisionRules.get_decision(ldr, buy, demand)\n@show LinearDecisionRules.get_decision(ldr, sell)\n@show LinearDecisionRules.get_decision(ldr, sell, demand)\n\n@show objective_value(ldr, dual = true)\n@show LinearDecisionRules.get_decision(ldr, buy, dual = true)","category":"page"},{"location":"","page":"LinearDecisionRules.jl Documentation","title":"LinearDecisionRules.jl Documentation","text":"We note:","category":"page"},{"location":"","page":"LinearDecisionRules.jl Documentation","title":"LinearDecisionRules.jl Documentation","text":"The model is built with LDRModel(), where we also set the solver that will be used for optimizing the reformulations;\nFirst-stage variables are created with the FirstStage attribute;\nThe uncertain variable demand is created using variable-in-set syntax, where the Uncertainty set is parametrized by a Distribution object;\nConstraints are interpreted \"for all scenarios\", and the objective is interpreted in expectation.","category":"page"},{"location":"#Syntax","page":"LinearDecisionRules.jl Documentation","title":"Syntax","text":"","category":"section"},{"location":"","page":"LinearDecisionRules.jl Documentation","title":"LinearDecisionRules.jl Documentation","text":"Declaring the model: ldr = LDRModel(optimizer);\nFirst-stage decision variables: @variable(ldr, x, FirstStage [, integer = true]);\nUnivariate uncertainties: @variable(ldr, ξ in Uncertainty(distribution = d)), where the distribution d has bounded support; also supports:\nUniform breakpoints: set_attribute(ξ, BreakPoints(), n_intervals - 1)\nList of breakpoints: set_attribute(ξ, BreakPoints(), v::Vector{Float64})\nMultivarite uncertainties: @variable(ldr, ξ[1:n] in Uncertainty(distribution = d))","category":"page"},{"location":"","page":"LinearDecisionRules.jl Documentation","title":"LinearDecisionRules.jl Documentation","text":"","category":"page"},{"location":"#LinearDecisionRules.get_decision","page":"LinearDecisionRules.jl Documentation","title":"LinearDecisionRules.get_decision","text":"get_decision(m, x, η; dual = false, piece = nothing)\n\nCoefficient of η in the LDR of x\n\n\n\n\n\nget_decision(m, x; dual = false)\n\nConstant term in the LDR of x\n\n\n\n\n\n","category":"function"}]
}
